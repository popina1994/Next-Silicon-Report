\documentclass[12pt]{article}

\input{defs.tex}

\geometry{a4paper, margin=1in}
\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}
\lhead{Djordje Zivanovic}

\title{Next Silicon: CM Home Assignment}
\author{Djordje Zivanovic \\ \small{LinScale}}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introduction}
This report \footnote{\href{https://github.com/popina1994/Next-Silicon-Report}{report}} contains the responses to the tasks stated in the home project pdf.
It is accompanied with the repository \footnote{\href{https://github.com/popina1994/next-silicon-maths}{next-silicon-maths}} that contains reproducible solutions with the installation instructions alongside: experiments and tests according to the task requirements.
\section{The Existing Implementation: Code Analysis and Documentation}
In this section we analyze the existing code shown in Algorithm \ref{alg:sine_existing}.

\subsection{Code Drawbacks}
The code is written for C and follows the following bad practices:
\begin{enumerate}
    \item Reusing the variable multiple times,  \texttt{(float)M\_PI} and \texttt{2.0f * (float)M\_PI}, (lines \ref{alg:sine_ex:ln:fmodf}, \ref{alg:sine_ex:ln:xGreater}, \ref{alg:sine_ex:ln:xLess}, \ref{alg:sine_ex:ln:xLess}, \ref{alg:sine_ex:ln:xMinus}, \ref{alg:sine_ex:ln:xPi} of Algorithm \ref{alg:sine_existing});
    \item Not using auto in order to automatically deduce types since the results of all the statements are known;
    \item Cleaning if loop to be more understandable: \texttt{fmodf} returns the result in the range $(-2 \pi, 2 \pi)$. Then, now it is obvious that one checks whether the number is outside of the range $[-\pi, \pi]$, and then updates \textbf{x} for $2 \pi$ period, so the further code operates with the number in the range $[-\pi, \pi]$;
    \item Adding more verbosity ();
    \item Reusing variable names -> more verbose names should be used in order to improve readability of the code. The c ompiler will optimize for the least number of variables/registers to be used;
    \item Renaming function names and migrating these functions to the corresponding headers and sources that would contain the custom maths functions.
\end{enumerate}

\input{algorithms/sine_existing.tex}

\subsection{Numerical and Implementation Drawbacks}
Here, I will give state several main drawbacks in terms of the implementation and numerical accuracy. The division by
In the next subsection, I will list the drawbacks related to the method itself.
\subsection{Mathematical Analysis}
Let us state the general Taylor series formula that is implemented in Algorithm \ref{alg:sine_existing}.
\begin{TheoremColor}{Theorem 5.19 from \protect{\cite[p.~113]{apostol1985mathematical}}}{taylor_formula}
    Let $f$ be a function having finite $n$-th derivative $f^{(n)}$
    everywhere in an open interval $(a, b)$ and assume that  $f^{(n-1)}$ is continuous on the closed interval $[a, b]$. Then, for every $x$ in $[a, b], x\neq c$, there exists a point $x_1$ interior to the interval joining $x$ and $c$ such that

    \begin{equation*}
        f(x) = f(c) + \sum_{k=1}^{n-1} \frac{f^{(k)}(c)(x-c)^{(k)}}{k!} + \frac{f^{(n)}(x_1)}{n!} (x - c)^n.
    \end{equation*}
\end{TheoremColor}
A corollary of Theorem \ref{th:taylor_formula} when we set $c = 0$ is a Maclaurin Series.
\begin{CorollaryColor}{Maclaurin Series}{Maclaurin}
    Let $f$ be a function having finite $n$-th derivative $f^{(n)}$
    everywhere in an open interval $(a, b)$ and assume that  $f^{(n-1)}$ is continuous on the closed interval $[a, b]$. Assume that $c \in [a, b]$. Then, for every $x$ in $[a, b], x\neq 0$, there exists a point $x_1$ interior to the interval joining $x$ and $0$ such that

    \begin{equation*}
        f(x) = f(0) + \sum_{k=1}^{n-1} \frac{f^{(k)}(0)(x)^{(k)}}{k!} + \frac{f^{(n)}(x_1)}{n!} x^n.
    \end{equation*}
\end{CorollaryColor}
Let us now set $a = -\pi, b= \pi$ and $f(x) = sin(x)$ .
The Maclaurin Series becomes for $\sin$ function:
\begin{CorollaryColor}{}{sine_mac}
    For $x \in \mathbb{R}, x\neq 0$ and $n \in \mathbb{N}$, and $0 < |x_1| < |x|$
    the approximation of a degree $n$ is
    \begin{equation*}
        sin(x) = \sum_{i=0}^{\lfloor\frac{n}{2}\rfloor}
        \left(-1\right)^{ i} \frac{x^{2i + 1}}{(2i+1)!}   +  L(x, n).
    \end{equation*}
    where
    \begin{equation*}
        L(x, n) = \begin{cases}
            \frac{f^{(n + 2)}x_1}{(n+2)!}x^{n+2}, & \text{if } n \bmod 2 = 0,  \\
            \frac{f^{(n + 1)}x_1}{(n+1)!}x^{n+1}, & \text{if } n \bmod 2 = 1.
          \end{cases}
    \end{equation*}
\end{CorollaryColor}
Thus, the method stated in Algorithm \ref{alg:sine_existing} has an algorithmic error $L(x, 7)$ which is smaller than $\frac{x^8}{8!}$.
Now, we obtain
\subsection{Accuracy and Correctness Failures} \label{subsec:acc_and_corr}
Based on Corollary \ref{cor:sine_mac}, we can notice that Algorithm \ref{alg:sine_existing} is incorrect for $x = 0$.
Similar, the farther the $x$ is from 0, the error is larger since $x^8$ grows exponentially.
There are several ways to solve these problems:

\subsection{Experiments}


The test plan will cover the following experiments:
\begin{enumerate}
    \item Different number distributions
    \begin{enumerate}
        \item Equally distanced numbers between certain multiplicands of $\frac{\pi}{2}$; We will vary the distance and provide statistical analysis with plots for each of such distance and multi`plicand.
        \item Normally distributed numbers around certain multiplicands of $\frac{\pi}{2}$; We will vary the variance and provide statistical analysis with plots for each of the multiplicands and variances.
    \end{enumerate}
    \item Edge cases
        \begin{enumerate}
            \item the multiplicands of $\frac{\pi}{2}$;
            \item large numbers (close to the absolute minimum  and maximum for the float numbers);
            \item normal distributions around the multiplicands of $\frac{\pi}{2}$;
            \item \texttt{nan}s.
        \end{enumerate}
    \item Numbers
\end{enumerate}
For each of these experiments we would compute the relative error in comparison to the value computed by the $\sin x$ provided in \texttt{cmath}.

\section{Additional Algorithms}
For the problems stated in Subsection \ref{subsec:acc_and_corr} there are several ways to approach:
\begin{enumerate}
    \item Have another Taylor series expansion for numbers around $\pi$ and $-\pi$. In this case we would manually calculate the $\sin x$ for $\pi$ and $-\pi$.
    \item  Add more terms in Taylor series expansion. It is important to find the optimal degree for the balance of accuracy and performance.
    \item Implement one or more of the alternative methods: Minimax Polynomial Approximation, Chebyshev Polynomial Expansion \cite{press2007numerical}, Lookup Table with Linear Interpolation and Lookup Table with Spline or Cubic Interpolation.
\end{enumerate}
Here we will focus on the implementation of the Chebyshev Polynomial Expansion.

\begin{DefinitionColor}{\cite[p~.233]{press2007numerical}}{cheb_poly}
    For a number $n\in \mathbb{N}$ and a real number $x$, the Chebyshev polynomial of degree $n$ is denoted $T_n(x)$ and defined as
    \begin{equation*}
        T_n(x) = \cos(n \arccos x).
    \end{equation*}
\end{DefinitionColor}

\begin{TheoremColor}{}{cheb_rec}
    For $n \in \mathbb{N}$,and $x \in \mathbb{R}$ the Chebyshev polynomial of degree $n$ satisfies the formula:
    \begin{equation*}
        T_n=2xT_n(x) - T_{n-1}(x),
    \end{equation*}
    where $T_0(x) =1$ and $T_1(x) = x$.
\end{TheoremColor}
Let us introduce definitions that would help with our computations.

\begin{DefinitionColor}{\cite[p~.234]{press2007numerical}}{cheb_coef}
    For a number $j, N\in \mathbb{N}$, the Chebyshev coefficient of degree $n$ is denoted $c_n(x)$ and defined as
    \begin{equation*}
        c_j(N) = \frac{2}{N} \sum_{k=0}^{N-1} f\left( \cos\left(  \frac{\pi(k+\frac{1}{2})}{N}\right)  \right) \cos \left(\frac{\pi j(k+\frac{1}{2})}{N}\right).
    \end{equation*}
\end{DefinitionColor}

Now the following formula holds:
\begin{TheoremColor}{}{cheb_approx}
    Let $N \in \mathbb{N}$, $x \in \mathbb{N}$, and a function $f : [-1, 1] \mapsto \mathbb{R}$.
    Let $f$ be a continuous and bounded function. Now, the follows holds:
    \begin{equation*}
        f(x) \approx \sum_{k=0}^{N-1} \left(c_k(N) \cdot T_k(x)\right) - \frac{1}{2} c_0(N).
    \end{equation*}
\end{TheoremColor}

We implement the approximation from Theorem \ref{th:cheb_approx} in Algorithm \ref{alg:sine_cheb_opt}.
Chebyshev coefficients are computed in Algorithm \ref{alg:cheb_coef}.
Since Chebyshev coefficients from Definition \ref{def:cheb_coef} are defined for the input $[-1, 1]$, but our input is in the range $[-\pi, \pi]$, we need to map the input to $[-1, 1]$ by uniformly scaling the input to this range (Algorithm \ref{alg:sine_cheb_opt} line \ref{alg:sine_cheb:ln:scaling}).
However, we have to scale back the input to $[-\pi, \pi]$ for the function $\texttt{f}$ in Algorithm \ref{alg:cheb_coef} (lines \ref{alg:sine_cheb:ln:scaling_back_0}, \ref{alg:sine_cheb:ln:scaling_back_1}, \ref{alg:sine_cheb:ln:scaling_back_2}).
The rest of Algorithm \ref{alg:cheb_coef} follows Definition \ref{def:cheb_coef}.
Algorithm \ref{alg:sine_cheb_opt} has two more improvements.
First, the algorithm uses the optimized \texttt{fmodf} for the accuracy implemented in the function \texttt{optimizedFModf2Pi} that maps the input from the set of real numbers to the set $[-2 \pi, 2 \pi]$.
Further, instead of following Theorem \ref{th:cheb_approx}, the algorithm implements Clenshaw's formula \cite[p~.237]{press2007numerical} for the better stability.

\input{algorithms/cheb_coef.tex}
\input{algorithms/cheb_approx.tex}

\bibliographystyle{plain}
\bibliography{refs}

\end{document}
